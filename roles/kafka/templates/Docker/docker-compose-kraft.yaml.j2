services:
  kafka:
    image: confluentinc/cp-kafka:{{ kafka_docker_version }}-{{ kafka_docker_tag }}
    container_name: {{ kafka_container_name }}
    hostname: {{ kafka_container_name }}
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --list --bootstrap-server={{ kafka_container_name }}:{{ kafka_port }} >/dev/null || exit 1"]
      interval: 5s
      timeout: 10s
      retries: 20
      start_period: 20s
    expose:
      - {{ kafka_port }}
      - {{ kafka_default_port }}
      - {{ kafka_controller_port }}
    ports:
      - {{ kafka_default_port }}:{{ kafka_default_port }}
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_BROKER_ID: 1
      KAFKA_CLUSTER_ID: '{{ kafka_cluster_id }}'
      KAFKA_LISTENERS: PLAINTEXT://{{ kafka_container_name }}:{{ kafka_port }},CONTROLLER://{{ kafka_container_name }}:{{ kafka_controller_port }},PLAINTEXT_HOST://{{ kafka_container_name }}:{{ kafka_default_port }}
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://{{ kafka_container_name }}:{{ kafka_port }},PLAINTEXT_HOST://{{ kafka_container_name }}:{{ kafka_default_port }}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_PROCESS_ROLES: "{{ kafka_server_roles }}"
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@{{ kafka_container_name }}:{{ kafka_controller_port }}'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: {{ kafka_offsets_topic_replication_factor }}
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: {{ kafka_group_initial_rebalance_delay_ms}}
      KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_CONFLUENT_BALANCER_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: {{ kafka_transaction_state_log_min_isr }}
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: {{ kafka_transaction_state_log_replication_factor }}
      KAFKA_LOG4J_ROOT_LOGLEVEL: {{ kafka_log4j_root_loglevel }}
      KAFKA_TOOLS_LOG4J_LOGLEVEL: {{ kafka_tools_log4j_loglevel }}
      KAFKA_LOG_RETENTION_HOURS: {{ kafka_log_retention_hours }}
      KAFKA_LOG_ROLL_MS: {{ kafka_log_roll_ms }}
      KAFKA_LOG_SEGMENT_BYTES: {{ kafka_log_segment_bytes }}
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: {{ kafka_log_retention_check_interval_ms }}
      KAFKA_MESSAGE_MAX_BYTES: {{ kafka_message_max_bytes }}
      KAFKA_RECEIVE_MESSAGE_MAX_BYTES: {{ kafka_receive_message_max_bytes }}
      KAFKA_REPLICA_FETCH_MAX_BYTES: {{ kafka_replica_fetch_max_bytes }}
      KAFKA_MAX_PARTITION_FETCH_BYTES: {{ kafka_max_partiton_fetch_bytes }}
      KAFKA_MAX_REQUEST_SIZE: {{ kafka_max_request_size }}
      KAFKA_RETENTION_MS: {{ kafka_retention_ms }}
      KAFKA_CLEANUP_POLICY: delete
    volumes:
      - data:/var/lib/kafka/data
      - ./files/enable-kraft.sh:/tmp/enable-kraft.sh
    command: "bash -c '/tmp/enable-kraft.sh && /etc/confluent/docker/run'"

  schema-registry:
    image: confluentinc/cp-schema-registry:{{ kafka_docker_version }}-{{ kafka_docker_tag }}
    container_name: {{ kafka_schema_registry_container_name }}
    hostname: {{ kafka_schema_registry_container_name }}
    restart: always
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: curl --fail --silent http://{{ kafka_schema_registry_container_name }}:{{ kafka_schema_registry_port }}/subjects --output /dev/null || exit 1
      interval: 5s
      timeout: 10s
      retries: 20
      start_period: 20s
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://{{ kafka_container_name }}:{{ kafka_port }}
      SCHEMA_REGISTRY_HOST_NAME: {{ kafka_schema_registry_container_name }}
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:{{ kafka_schema_registry_port }}
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: PLAINTEXT
      SCHEMA_REGISTRY_LOG4J_ROOT_LOGLEVEL: {{ kafka_schema_registry_log4j_root_loglevel }}
      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
    expose:
      - {{ kafka_schema_registry_port }}

  connect:
    image: confluentinc/cp-kafka-connect:{{ kafka_docker_version }}-{{ kafka_docker_tag }}
    container_name: {{ kafka_connect_container_name }}
    hostname: {{ kafka_connect_container_name }}
    restart: always
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
    healthcheck:
      interval: 15s
      retries: 10
      start_period: 60s
      test: curl --fail --silent http://{{ kafka_connect_container_name }}:{{ kafka_connect_port }}/ --output /dev/null || exit 1
    environment:
      CONNECT_BOOTSTRAP_SERVERS: {{ kafka_container_name }}:{{ kafka_port }}
      CONNECT_REST_ADVERTISED_HOST_NAME: {{ kafka_connect_container_name }}
      CONNECT_REST_PORT: {{ kafka_connect_port }}
      CONNECT_GROUP_ID: compose-connect-group
      CONNECT_CONFIG_STORAGE_TOPIC: docker-connect-configs
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_OFFSET_FLUSH_INTERVAL_MS: 10000
      CONNECT_OFFSET_STORAGE_TOPIC: docker-connect-offsets
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_STATUS_STORAGE_TOPIC: docker-connect-status
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: 1
      CONNECT_KEY_CONVERTER: {{ kafka_connect_key_converter }}
      CONNECT_VALUE_CONVERTER: {{ kafka_connect_value_converter }}
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: http://{{ kafka_schema_registry_container_name }}:{{ kafka_schema_registry_port }}
      CONNECT_INTERNAL_KEY_CONVERTER: {{ kafka_connect_internal_key_converter }}
      CONNECT_INTERNAL_VALUE_CONVERTER: {{ kafka_connect_internal_value_converter }}
      CONNECT_PRODUCER_INTERCEPTOR_CLASSES: {{ kafka_connect_producer_interceptor_classes }}
      CONNECT_CONSUMER_INTERCEPTOR_CLASSES: {{ kafka_connect_consumer_interceptor_classes }}
      CONNECT_PLUGIN_PATH: {{ kafka_connect_plugin_path }}
      CONNECT_LOG4J_ROOT_LOGGER: {{ kafka_connect_log4j_root_logger }}
      CONNECT_FETCH_MESSAGE_MAX_BYTES: {{ kafka_connect_fetch_message_max_bytes }}
      CONNECT_MAX_REQUEST_SIZE: {{ kafka_connect_max_request_size }}
      CONNECT_MAX_PARTITION_FETCH_BYTES: {{ kafka_connect_max_partition_fetch_bytes }}
      CONNECT_REBALANCE_TIMEOUT_MS: {{ kafka_connect_rebalance_timeout_ms }}
      CONNECT_SCHEDULED_REBALANCE_MAX_DELAY_MS: {{ kafka_connect_scheduled_rebalance_max_delay_ms }}
#      CONNECT_PRODUCER_MAX_REQUEST_SIZE: {{ kafka_connect_producer_max_request_size }}
#      CONNECT_CONSUMER_MAX_PARTITION_FETCH_BYTES: {{ kafka_connect_consumer_max_partition_fetch_bytes }}
    expose:
      - {{ kafka_connect_port }}
    volumes:
      - ./files/kafka-connect-arangodb:/usr/share/java/kafka-connect-arangodb

  init-kafka:
    build:
      context: build_check
    container_name: init-kafka
    restart: unless-stopped
    depends_on:
      connect:
        condition: service_healthy
    healthcheck:
      test: ["CMD-SHELL", "/work/check.sh {{ kafka_connect_container_name }}"]
      interval: 60s
      timeout: 5s
      retries: 3
      start_period: 120s

  kafka-ui:
    container_name: {{ kafka_ui_container_name }}
    hostname: {{ kafka_ui_container_name }}
    image: provectuslabs/kafka-ui:latest
    depends_on:
      kafka:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      connect:
        condition: service_healthy
    expose:
      - {{ kafka_ui_port }}
    restart: always      
    environment:
      KAFKA_CLUSTERS_0_NAME: KAFKA-CLUSTER
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: {{ kafka_container_name }}:{{ kafka_port }}
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://{{ kafka_schema_registry_container_name }}:{{ kafka_schema_registry_port }}
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_NAME: KAFKA-CONNECT
      KAFKA_CLUSTERS_0_KAFKACONNECT_0_ADDRESS: http://{{ kafka_connect_container_name }}:{{ kafka_connect_port }}

networks:
  default:
    name: {{ kafka_net }}
    external: true
volumes:
  data:
